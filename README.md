# 16S rRNA Novelty Screening Pipeline

A reproducible, production-oriented **Snakemake pipeline** for screening 16S rRNA gene sequencing data to identify **potentially novel bacterial taxa**.

This pipeline is designed to turn raw amplicon sequencing data into **clear, auditable novelty calls** (`KNOWN`, `POTENTIALLY_NOVEL`, `INCONCLUSIVE`), with explicit handling of ambiguity, controls, and biological limitations.

---

## üéØ Project Goals

- Provide a **robust screening workflow** for detecting candidate novel taxa from 16S data  
- Emphasize **traceability, reproducibility, and conservative decision-making**
- Demonstrate production-quality pipeline design (not just analysis scripts)

This project is intentionally framed as **novelty screening**, not formal species discovery.

---

## üß† Design Principles

- **ASV-based inference (DADA2)** for maximum biological resolution and reproducibility
- **Explicit decision logic** with documented thresholds and reasons
- **Strong I/O contracts**: each step produces predictable, versioned artifacts
- **Deterministic inputs** via a manifest file
- **Separation of concerns**: workflow orchestration (Snakemake) vs logic (Python/R)
- **Production-ready structure**: scalable, debuggable, safe to re-run

---

## üß¨ Pipeline Overview

Raw FASTQ

‚Üì

Primer trimming & QC (cutadapt, FastQC)

‚Üì

Denoising & ASV inference (DADA2)

‚Üì

Taxonomic assignment (SILVA trainset)

‚Üì

Novelty decision logic

‚Üì

Per-sample call + metrics


### Core Outputs (per sample)
- `call.json` ‚Äî final classification + reasons + provenance
- `metrics.tsv` ‚Äî summary metrics for downstream analysis
- ASV tables and representative sequences
- Logs for each pipeline stage

---

## üìÇ Repository Structure
.
‚îú‚îÄ‚îÄ Snakefile

‚îú‚îÄ‚îÄ config/

‚îÇ ‚îî‚îÄ‚îÄ config.yaml

‚îú‚îÄ‚îÄ data/

‚îÇ ‚îî‚îÄ‚îÄ manifest.tsv

‚îú‚îÄ‚îÄ workflow/

‚îÇ ‚îú‚îÄ‚îÄ envs/ # Conda environments

‚îÇ ‚îú‚îÄ‚îÄ scripts/ # Python/R logic

‚îÇ ‚îî‚îÄ‚îÄ rules/ # Snakemake rules

‚îú‚îÄ‚îÄ resources/

‚îÇ ‚îî‚îÄ‚îÄ db/README.md # Reference DB instructions

‚îî‚îÄ‚îÄ README.md


**Note:**  
Raw sequencing data, reference databases, logs, and results are intentionally **excluded from version control** and regenerated deterministically.

---

## üìÑ Input Manifest (Deterministic Inputs)

All samples are defined explicitly in a tab-delimited manifest:

```tsv
sample        read1                     read2                     sample_type
TEST_F3D146   data/...R1.fastq.gz       data/...R2.fastq.gz       test
NEG_BLANK     data/...R1.fastq.gz       data/...R2.fastq.gz       negative
POS_MOCK      data/...R1.fastq.gz       data/...R2.fastq.gz       positive
```
---
**üß™ Denoising & ASVs (Why ASVs > OTUs)**
* This pipeline uses Amplicon Sequence Variants (ASVs) rather than OTUs.
* Why:
  - ASVs represent exact biological sequences
  - Reproducible across runs and datasets
  - Preserve subtle sequence differences important for novelty detection
  - Avoid arbitrary clustering thresholds
* Denoising models sequencing error to separate true biological variation from noise.

**üß† Novelty Decision Logic (v0)**

* The pipeline makes a conservative screening call:
* Decision categories
  - KNOWN ‚Üí At least one ASV confidently assigned to a known genus
  - POTENTIALLY_NOVEL ‚Üí Sufficient signal, but no genus-level assignment
  - INCONCLUSIVE ‚Üí Insufficient data, failed QC, or control issues
* Key principles
  - Negative controls are evaluated first
  - Low read depth or too few ASVs ‚Üí no over-interpretation
  - Novelty indicates candidates for follow-up, not formal species claims
* All decisions include explicit reasons and supporting metrics.

** üîÅ Reproducibility & Provenance**
* Each run is reproducible and auditable via:
  - manifest-defined inputs
  - versioned pipeline code
  - recorded thresholds
  - reference database versioning
  - per-sample provenance metadata
* Outputs can be safely regenerated or compared across runs.

üöÄ Running the Pipeline
* Requirements
  - Snakemake
  - Conda / Mamba
  - Linux environment (local, HPC, or cloud)
* Example
```snakemake -j 16```
* The same workflow can scale to clusters or cloud executors using Snakemake profiles.

‚ö†Ô∏è Limitations (By Design)
* 16S cannot resolve all species (e.g. closely related taxa)
* Novelty is relative to reference databases
* Final species confirmation requires:
  - full-length 16S, and/or
  - isolate sequencing, and/or
  - whole-genome data
* This pipeline is intentionally conservative to avoid false novelty claims.

üìå Future Extensions
* Phylogenetic placement for borderline cases
* Cross-database taxonomy comparison
* Integration with isolate/WGS workflows
* Persistent metadata storage (e.g. SQLite/Postgres)
* Automated reprocessing on DB updates
